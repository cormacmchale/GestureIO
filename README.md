# Gesture IO
 _4th year Gesture Based UI Development project. This project uses machine learning and neural networks to allow users to perform certain actions by with specific gestures. This project utilises the device's webcam and captures a gesture performed by the user. This gesture is then processed and compared against a model, trained using our own gestures. If the model recognises a gesture performed, an action tied to that gesture will then be performed (such as opening a URL or opening a program on the device._
<div style="text-align:absolute"><img src="https://github.com/cormacmchale/SignWriter/blob/master/images/ef6e61f1-aa83-4aa1-880b-c93a8769a931_200x200.png" /></div>

### Developers
* Cormac McHale
* Kevin Niland

### Development
* **Language:** Python
* **Using:** Computers

## How it works
<div style="text-align:center"><img src="https://github.com/cormacmchale/SignWriter/blob/master/images/project_flow_diagram.PNG" /></div>

## The model

## Capturing the gesture
